{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное задание:\n",
    "Даны выборки для обучения и для тестирования. Задание заключается в том, чтобы попробовать разные способы валидации, проанализировать плюсы / минусы каждой и сделать выводы о том, какой способ валидации наиболее устойчивый в данной задаче. Метрика качества для оценки прогнозов - ROC-AUC, название целевой переменной - IsFraud. Рекомендуется использовать модели градиетного бустинга, реализация любая / гипепараметры любые. Внимание! выборка assignment_2_test.csv - наш аналог лидерборда. Будем моделировать ситуацию отправки решения на лидерборд и сравнить значение метрики на лидерборде и на локальной валидации. Для других целей использовать выборку запрещено!.\n",
    "\n",
    "Терминалогия, используемая в задании:\n",
    "* обучающая выборка - выборка, которая передается в метод\n",
    "fit\n",
    "/\n",
    "train\n",
    ";\n",
    "* валидационная выборка - выборка, которая получается при Hold-Out на 2 выборки (\n",
    "train\n",
    ",\n",
    "valid\n",
    ");\n",
    "* тестовая выборка - выборка, которая получается при Hold-Out на 3 выборки (\n",
    "train\n",
    ",\n",
    "valid\n",
    ",\n",
    "test\n",
    ");\n",
    "* ЛБ - лидерборд, выборка\n",
    "assignment_2_test.csv\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../lesson_2/assignment_2_train.csv')\n",
    "leader_board = pd.read_csv('../lesson_2/assignment_2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 394)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('TransactionID', ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'isFraud'\n",
    "x_columns = [col for col in df.columns if col != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of object_features 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ProductCD',\n",
       " 'card4',\n",
       " 'card6',\n",
       " 'P_emaildomain',\n",
       " 'R_emaildomain',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_features = df.select_dtypes(include=[np.object])\n",
    "print(f\"count of object_features {object_features.shape[1]}\")\n",
    "\n",
    "object_features_col = list(object_features.columns)\n",
    "object_features_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка категориальных признаков\n",
    "for feature in object_features:\n",
    "    namber_val = 0\n",
    "    for unic_val in df[feature].unique():\n",
    "        namber_val += 1\n",
    "        df.loc[df[feature] == unic_val, feature] = namber_val\n",
    "        leader_board.loc[leader_board[feature] == unic_val, feature] = namber_val\n",
    "    df[feature] = pd.to_numeric(df[feature])\n",
    "    leader_board[feature] = pd.to_numeric(leader_board[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1:\n",
    "\n",
    "Сделать Hold-Out валидацию с разбиением, размер которого будет адеквтаным, по вашему мнению; разбиение проводить по id-транзакции (\n",
    "TransactionID\n",
    "), обучать модель градиетного бустинга любой реализации с подбором числа деревьев по early_stopping критерию до достижения сходимости. Оценить качество модели на валидационной выборке, оценить расхождение по сравнению с качеством на обучающей выборке и валидационной выборке. Оценить качество на ЛБ, сравнить с качеством на обучении и валидации. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[:round(df.shape[0]*0.8)][x_columns]\n",
    "y_train = df[:round(df.shape[0]*0.8)][target]\n",
    "x_valid = df[round(df.shape[0]*0.8):df.shape[0]][x_columns]\n",
    "y_valid = df[round(df.shape[0]*0.8):df.shape[0]][target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "#     \"n_estimators\": 100,\n",
    "    \"reg_lambda\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"gamma\": 10,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.64131\tvalid-auc:0.63913\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.79264\tvalid-auc:0.79753\n",
      "[20]\ttrain-auc:0.86040\tvalid-auc:0.84586\n",
      "[30]\ttrain-auc:0.87652\tvalid-auc:0.85310\n",
      "[40]\ttrain-auc:0.89047\tvalid-auc:0.86075\n",
      "[50]\ttrain-auc:0.90219\tvalid-auc:0.86481\n",
      "[60]\ttrain-auc:0.91023\tvalid-auc:0.87490\n",
      "[70]\ttrain-auc:0.91608\tvalid-auc:0.88086\n",
      "[80]\ttrain-auc:0.91976\tvalid-auc:0.88455\n",
      "[90]\ttrain-auc:0.92274\tvalid-auc:0.88649\n",
      "[100]\ttrain-auc:0.92517\tvalid-auc:0.88859\n",
      "[110]\ttrain-auc:0.92685\tvalid-auc:0.89054\n",
      "[120]\ttrain-auc:0.92832\tvalid-auc:0.89216\n",
      "[130]\ttrain-auc:0.92931\tvalid-auc:0.89254\n",
      "[140]\ttrain-auc:0.92976\tvalid-auc:0.89300\n",
      "[150]\ttrain-auc:0.92976\tvalid-auc:0.89300\n",
      "Stopping. Best iteration:\n",
      "[133]\ttrain-auc:0.92976\tvalid-auc:0.89300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(\n",
    "    data=x_train, label=y_train\n",
    ")\n",
    "dvalid = xgb.DMatrix(\n",
    "    data=x_valid, label=y_valid\n",
    ")\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=300,\n",
    "    early_stopping_rounds=20,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    verbose_eval=10,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xgb_model_1.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8702878377416603"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlid_board = xgb.DMatrix(\n",
    "    data=leader_board[x_columns], label=leader_board[target]\n",
    ")\n",
    "predict_val = model.predict(dlid_board)\n",
    "roc_auc_score(leader_board[target], predict_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "В данной ситуации, нельзя сделать однозначные выводы переобучилась модель или нет. С одной стороны score на тренировочной и валидационной выборках больше чем на лидерборде, что может свидетельствовать о переобучении модели. Но разница не очень велика и мы не имеем дополнительной информации о распределении score на валидационной и тренировочной выборках для однозначного ответа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2:\n",
    "\n",
    "Сделать Hold-Out валидацию с разбиением на 3 выборки, разбиение проводить по id-транзакции (TransactionID), размер каждой выборки подобрать самостоятельно. Повторить процедуру из п.1. для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[:round(df.shape[0]*0.8)][x_columns]\n",
    "y_train = df[:round(df.shape[0]*0.8)][target]\n",
    "x_valid = df[round(df.shape[0]*0.8):round(df.shape[0]*0.9)][x_columns]\n",
    "y_valid = df[round(df.shape[0]*0.8):round(df.shape[0]*0.9)][target]\n",
    "x_test = df[round(df.shape[0]*0.9):df.shape[0]][x_columns]\n",
    "y_test = df[round(df.shape[0]*0.9):df.shape[0]][target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.64131\tvalid-auc:0.63470\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.79264\tvalid-auc:0.80565\n",
      "[20]\ttrain-auc:0.86040\tvalid-auc:0.85785\n",
      "[30]\ttrain-auc:0.87652\tvalid-auc:0.86533\n",
      "[40]\ttrain-auc:0.89047\tvalid-auc:0.87233\n",
      "[50]\ttrain-auc:0.90219\tvalid-auc:0.87640\n",
      "[60]\ttrain-auc:0.91023\tvalid-auc:0.88529\n",
      "[70]\ttrain-auc:0.91608\tvalid-auc:0.89012\n",
      "[80]\ttrain-auc:0.91976\tvalid-auc:0.89298\n",
      "[90]\ttrain-auc:0.92274\tvalid-auc:0.89504\n",
      "[100]\ttrain-auc:0.92517\tvalid-auc:0.89735\n",
      "[110]\ttrain-auc:0.92685\tvalid-auc:0.89850\n",
      "[120]\ttrain-auc:0.92832\tvalid-auc:0.89962\n",
      "[130]\ttrain-auc:0.92931\tvalid-auc:0.90015\n",
      "[140]\ttrain-auc:0.92976\tvalid-auc:0.90058\n",
      "[150]\ttrain-auc:0.92976\tvalid-auc:0.90058\n",
      "Stopping. Best iteration:\n",
      "[133]\ttrain-auc:0.92976\tvalid-auc:0.90058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(\n",
    "    data=x_train, label=y_train\n",
    ")\n",
    "dvalid = xgb.DMatrix(\n",
    "    data=x_valid, label=y_valid\n",
    ")\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=300,\n",
    "    early_stopping_rounds=20,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    verbose_eval=10,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xgb_model_2.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC for test: 0.8858630883567298 \n",
      "ROC_AUC for lider board: 0.8702878377416603\n"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(\n",
    "    data=x_test, label=y_test\n",
    ")\n",
    "dlid_board = xgb.DMatrix(\n",
    "    data=leader_board[x_columns], label=leader_board[target]\n",
    ")\n",
    "predict_val_test = model.predict(dtest)\n",
    "predict_val_lb = model.predict(dlid_board)\n",
    "\n",
    "metric_test = roc_auc_score(y_test, predict_val_test)\n",
    "metric_lb = roc_auc_score(leader_board[target], predict_val_lb)\n",
    "\n",
    "print(f'ROC_AUC for test: {metric_test} \\nROC_AUC for lider board: {metric_lb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "Ситуации повторяется. Нельзя сделать однозначные выводы переобучилась модель или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3:\n",
    "\n",
    "Построить доверительный интервал на данных из п.2 на основе бутстреп выборок, оценить качество модели на ЛБ относительно полученного доверительного интервала. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8701854077880476, 0.9005647109737781)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(27)\n",
    "scores = create_bootstrap_metrics(y_test, predict_val_test, roc_auc_score)\n",
    "\n",
    "calculate_confidence_interval(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8634762507957352, 0.876603369553642)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(27)\n",
    "scores = create_bootstrap_metrics(leader_board[target], predict_val_lb, roc_auc_score)\n",
    "\n",
    "calculate_confidence_interval(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "После проведения дополнительного исследования, можно сделать вывод о том что метрика качества находится в пределах доверительного интервала. Поэтому можно сказать что модель обучилась хорошо и ей можно доверять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4:\n",
    "\n",
    "Выполнить Adversarial Validation, подобрать объекты из обучающей выборки, которые сильно похожи на объекты из assignment_2_test.csv, и использовать их в качестве валидационного набора. Оценить качество модели на ЛБ, сделать выводы о полученных результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv = pd.concat([\n",
    "    x_train, x_valid], axis=0\n",
    ")\n",
    "y_adv = np.hstack((np.zeros(x_train.shape[0]), np.ones(x_valid.shape[0])))\n",
    "assert x_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=25)\n",
    "model.fit(x_adv, y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_adv = model.predict_proba(x_adv)\n",
    "score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "print(round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       ...,\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(x_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]    144000\n",
       "(0.1, 0.2]         0\n",
       "(0.2, 0.3]         0\n",
       "(0.3, 0.4]         0\n",
       "(0.4, 0.5]         0\n",
       "(0.5, 0.6]         0\n",
       "(0.6, 0.7]         0\n",
       "(0.7, 0.8]         0\n",
       "(0.8, 0.9]         0\n",
       "(0.9, 1.0]         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    y_pred[:, 1], bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5:\n",
    "\n",
    "Сделать KFold / StratifiedKFold валидацию (на ваше усмотрение), оценить получаемые качество и разброс по метрике качества. Сделать выводы об устойчивости кросс-валидации, сходимости оценки на кросс-валидации и отложенном наборе данных; Оценить качество на ЛБ, сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=20,\n",
       "             eval_metric='auc', gamma=10, gpu_id=-1, importance_type='gain',\n",
       "             interaction_constraints=None, learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=10, maximize=True, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=0,\n",
       "             num_boost_round=300, num_parallel_tree=1,\n",
       "             objective='binary:logistic', random_state=27, reg_alpha=0,\n",
       "             reg_lambda=100, scale_pos_weight=1, seed=27, subsample=1,\n",
       "             tree_method=None, ...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t = xgb.XGBRegressor(\n",
    "    eval_metric=\"auc\",\n",
    "    booster=\"gbtree\",\n",
    "    objective=\"binary:logistic\",\n",
    "    learning_rate=0.1,\n",
    "    reg_lambda=100,\n",
    "    max_depth=10,\n",
    "    gamma=10,\n",
    "    seed=27,\n",
    "    num_boost_round=300,\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    "    maximize=True,)\n",
    "\n",
    "model_t.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-score: 0.925, Valid-score: 0.897, Test-score: 0.88\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, model_t.predict(x_train))\n",
    "valid_score = roc_auc_score(y_valid, model_t.predict(x_valid))\n",
    "test_score = roc_auc_score(y_test, model_t.predict(x_test))\n",
    "\n",
    "print(f\"Train-score: {round(train_score, 3)}, Valid-score: {round(valid_score, 3)}, Test-score: {round(test_score, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-results: 0.904 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(\n",
    "    estimator=model_t,\n",
    "    X=df[x_columns],\n",
    "    y=df[target],\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "print(f\"CV-results: {round(np.mean(cv), 4)} +/- {round(np.std(cv), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(X: pd.DataFrame,\n",
    "                          y: pd.Series,\n",
    "                          estimator: object,\n",
    "                          metric: callable,\n",
    "                          cv_strategy):\n",
    "    \"\"\"\n",
    "    Кросс-валидация.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.DataFrame\n",
    "        Матрица признаков.\n",
    "\n",
    "    y: pd.Series\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    estimator: callable\n",
    "        Объект модели для обучения.\n",
    "\n",
    "    metric: callable\n",
    "        Метрика для оценки качества решения.\n",
    "        Ожидается, что на вход будет передана функция,\n",
    "        которая принимает 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    cv_strategy: cross-validation generator\n",
    "        Объект для описания стратегии кросс-валидации.\n",
    "        Ожидается, что на вход будет передан объект типа\n",
    "        KFold или StratifiedKFold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    oof_score: float\n",
    "        Значение метрики качества на OOF-прогнозах.\n",
    "\n",
    "    fold_train_scores: List[float]\n",
    "        Значение метрики качества на каждом обучающем датасете кросс-валидации.\n",
    "\n",
    "    fold_valid_scores: List[float]\n",
    "        Значение метрики качества на каждом валидационном датасете кросс-валидации.\n",
    "\n",
    "    oof_predictions: np.array\n",
    "        Прогнозы на OOF.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, fold_train_scores, fold_valid_scores = [], [], []\n",
    "    oof_predictions = np.zeros(X.shape[0])\n",
    "\n",
    "    for fold_number, (train_idx, valid_idx) in enumerate(cv_strategy.split(X, y)):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "\n",
    "        estimator.fit(x_train, y_train)\n",
    "        y_train_pred = estimator.predict(x_train)\n",
    "        y_valid_pred = estimator.predict(x_valid)\n",
    "\n",
    "        fold_train_scores.append(metric(y_train, y_train_pred))\n",
    "        fold_valid_scores.append(metric(y_valid, y_valid_pred))\n",
    "        oof_predictions[valid_idx] = y_valid_pred\n",
    "\n",
    "        msg = (\n",
    "            f\"Fold: {fold_number+1}, train-observations = {len(train_idx)}, \"\n",
    "            f\"valid-observations = {len(valid_idx)}\\n\"\n",
    "            f\"train-score = {round(fold_train_scores[fold_number], 4)}, \"\n",
    "            f\"valid-score = {round(fold_valid_scores[fold_number], 4)}\" \n",
    "        )\n",
    "        print(msg)\n",
    "        print(\"=\"*69)\n",
    "        estimators.append(estimator)\n",
    "\n",
    "    oof_score = metric(y, oof_predictions)\n",
    "    print(f\"CV-results train: {round(np.mean(fold_train_scores), 4)} +/- {round(np.std(fold_train_scores), 3)}\")\n",
    "    print(f\"CV-results valid: {round(np.mean(fold_valid_scores), 4)} +/- {round(np.std(fold_valid_scores), 3)}\")\n",
    "    print(f\"OOF-score = {round(oof_score, 4)}\")\n",
    "\n",
    "    return estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksandr/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.929, valid-score = 0.8887\n",
      "=====================================================================\n",
      "Fold: 2, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.9292, valid-score = 0.9025\n",
      "=====================================================================\n",
      "Fold: 3, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.9248, valid-score = 0.9139\n",
      "=====================================================================\n",
      "Fold: 4, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.9263, valid-score = 0.8988\n",
      "=====================================================================\n",
      "Fold: 5, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.925, valid-score = 0.8881\n",
      "=====================================================================\n",
      "CV-results train: 0.9269 +/- 0.002\n",
      "CV-results valid: 0.8984 +/- 0.01\n",
      "OOF-score = 0.8981\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions = make_cross_validation(\n",
    "    df[x_columns], df[target], model_t, metric=roc_auc_score, cv_strategy=cv_strategy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "После проведения кросс-валидации можно сказать что модель достаточно стабильна. Разброс метрики качества очень мальенький."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6 (опциональное):\n",
    "\n",
    "сделать Hold-Out валидацию по времени (TransactionDT), повторить процедуры из п.1 / п.2 (на ваш выбор). Построить доверительный интервал, сравнить качество на ЛБ выборке с полученным доверительным интервалом. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7 (совсем опциональное):\n",
    "\n",
    "в данном наборе данных у нас есть ID-транзакции (TransactionID) и время транзакции (TransactionDT), но отсутствует ID-клиента, который совершал транзакции. Кажется, что в этой задаче валидация по клиенту работала бы хорошо. Предложить критерий, по которому можно выделить клиентов и сделать п.5, используя созданное определение клиента, используя валидацию по клиенту (GroupKFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
